# RAG_from_scratch


## RAG (Retrieval-Augmented Generation) from Scratch â€“ End-to-End System
* Designed and implemented a RAG pipeline from scratch using sentence-transformers, FAISS, and PyMuPDF for semantic document search and PDF parsing.
* Manually handled vector store creation, embedding generation, and LLM querying, without relying on high-level frameworks like LangChain or Haystack.
* Optimized LLM inference with bitsandbytes, accelerate, and flash-attn, ensuring memory-efficient, low-latency responses.
* Built and tested in a GPU-accelerated Colab environment, utilizing torch, tqdm, and requests for scalable data handling and performance tracking.
